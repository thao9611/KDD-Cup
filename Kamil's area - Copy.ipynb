{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {}\n",
    "dataset['paper'] = pd.read_csv('dataRev2/Paper.csv').fillna(\"\")\n",
    "dataset['author'] = pd.read_csv('dataRev2/Author.csv').fillna(\"\")\n",
    "dataset['conference'] = pd.read_csv('dataRev2/Conference.csv').fillna(\"\")\n",
    "dataset['journal'] = pd.read_csv('dataRev2/Journal.csv').fillna(\"\")\n",
    "dataset['paper_author'] = pd.read_csv('dataRev2/PaperAuthor.csv').fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_paper_ids(paper_ids_string):\n",
    "    return paper_ids_string.strip().split()\n",
    "\n",
    "def parse_targetset(targetset):\n",
    "    pair_list = []\n",
    "    author_id_list = targetset['AuthorId']\n",
    "\n",
    "    for i in range(len(author_id_list)):\n",
    "        author_id = author_id_list[i]\n",
    "        papers = targetset[targetset.AuthorId == author_id]['PaperIds'].unique()[0]\n",
    "        papers = parse_paper_ids(papers)\n",
    "        for j in range(len(papers)):\n",
    "            paper_id = int(papers[j])\n",
    "            pair_list.append( (author_id, paper_id) )\n",
    "    return list(set(pair_list))\n",
    "\n",
    "def generate_feature_list(author_paper_pairs, ap_to_feature_list):\n",
    "    result_list = []\n",
    "\n",
    "    temp_dict = {} # { (author, paper) => [f1, f2 ...] }\n",
    "    for ap_pair in author_paper_pairs:\n",
    "        temp_dict[ap_pair] = []\n",
    "\n",
    "    for i in range(len(ap_to_feature_list)):\n",
    "        feature_dict = ap_to_feature_list[i]\n",
    "        for ap_pair in author_paper_pairs:\n",
    "            feature = feature_dict[ap_pair]\n",
    "            temp_dict[ap_pair].append(feature)\n",
    "\n",
    "    for key in temp_dict.keys():\n",
    "        result_list.append(key + tuple( temp_dict[key] ))\n",
    "\n",
    "    return result_list\n",
    "\n",
    "def lcs(X , Y):\n",
    "    # find the length of the strings\n",
    "    m = len(X)\n",
    "    n = len(Y)\n",
    " \n",
    "    # declaring the array for storing the dp values\n",
    "    L = np.zeros((m+1,n+1))\n",
    " \n",
    "    \"\"\"Following steps build L[m+1][n+1] in bottom up fashion\n",
    "    Note: L[i][j] contains length of LCS of X[0..i-1]\n",
    "    and Y[0..j-1]\"\"\"\n",
    "    for i in range(m+1):\n",
    "        for j in range(n+1):\n",
    "            if i == 0 or j == 0 :\n",
    "                L[i][j] = 0\n",
    "            elif X[i-1] == Y[j-1]:\n",
    "                L[i][j] = L[i-1][j-1]+1\n",
    "            else:\n",
    "                L[i][j] = max(L[i-1][j] , L[i][j-1])\n",
    " \n",
    "    # L[m][n] contains the length of LCS of X[0..n-1] & Y[0..m-1]\n",
    "    return L[m][n]\n",
    "\n",
    "def get_coauthor_aff(pa_data,pid):\n",
    "    related_authors = pa_data[pa_data['PaperId'] == pid]['Affiliation']\n",
    "    return related_authors.unique()\n",
    "\n",
    "def kamil_feature_11(dataset, author_paper_pairs):\n",
    "    feature_dict = {}\n",
    "    pa_data = dataset[\"paper_author\"].set_index('AuthorId')\n",
    "    \n",
    "    print(\"Welcome to Kamil's feature!\")\n",
    "    print(\"AP shape\",len(author_paper_pairs))\n",
    "    print(\"type\",type(author_paper_pairs[0][0]))\n",
    "    \n",
    "    for ap in author_paper_pairs:\n",
    "        #print(\"PA pair\",ap)\n",
    "        #paper_aff = pa_data.loc[(pa_data.loc[ap[0]][\"PaperId\"] == ap[1])][\"Affiliation\"].unique()\n",
    "        #print(\"Paper aff--\",paper_aff,\"--\")\n",
    "        \n",
    "        ta_aff = \" \".join(pa_data.loc[ap[0]][\"Affiliation\"].unique())\n",
    "        #print(\"Target aff--\",ta_aff,\"--\")\n",
    "        coa_aff = get_coauthor_aff(pa_data, ap[1])\n",
    "        value = 0\n",
    "        for i,aff in enumerate(coa_aff):\n",
    "            if(aff != \"\"):\n",
    "         #       print(i,\"Co auth aff::\",aff,\"::\")\n",
    "                value += lcs(aff, ta_aff)\n",
    "        feature_dict[ap] = value\n",
    "        #print(ap,\" -> \",value)\n",
    "    return feature_dict\n",
    "\n",
    "def get_features(dataset, targetset):\n",
    "    author_paper_pairs = parse_targetset(targetset)\n",
    "\n",
    "    # Keep the format of f# (dictionary): { (a1, p1): feature_value1, (a2, p2): feature_value2 ... }\n",
    "    # Add your features here and add them to feature_list!\n",
    "    kamil_f1 = kamil_feature_11(dataset, author_paper_pairs)\n",
    "    kamil_list = [kamil_f1]\n",
    "    \n",
    "    thao_list,harry_list = [],[]\n",
    "    feature_list = harry_list + kamil_list + thao_list\n",
    "\n",
    "    result_list = generate_feature_list(author_paper_pairs, feature_list)\n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sample_l = [(1539933, 1359549), (1455231, 467172), (1215636, 1791266), (205278, 1737961), (433821, 1901940)]\n",
    "#521630,1 + 972575,1\n",
    "#kamil_feature_11(dataset,sample_l)\n",
    "#toy = dataset[\"paper_author\"].set_index('AuthorId')\n",
    "#toy.loc[972575][\"PaperId\"] == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to Kamil's feature!\n",
      "AP shape 126\n",
      "type <class 'numpy.int64'>\n",
      "Wall time: 5min 14s\n"
     ]
    }
   ],
   "source": [
    "trainset = pd.read_csv('dataRev2/Train.csv')\n",
    "train_confirmed = trainset[['AuthorId', 'ConfirmedPaperIds']].rename(columns = {'ConfirmedPaperIds':'PaperIds'})\n",
    "#train_confirmed.head(5)\n",
    "%time features_conf = get_features(dataset, train_confirmed.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PaperIds</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AuthorId</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>25733 47276 77012 79468 87141 101385 104556 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>1739240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118</th>\n",
       "      <td>49963 93433 341015 415282 488635 517119 521922...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2783</th>\n",
       "      <td>154377 212636 334024 350747 696269 704564 1241...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3105</th>\n",
       "      <td>603562 647574 792910 844605 863071 878798 1082...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   PaperIds\n",
       "AuthorId                                                   \n",
       "826       25733 47276 77012 79468 87141 101385 104556 11...\n",
       "933                                                 1739240\n",
       "1118      49963 93433 341015 415282 488635 517119 521922...\n",
       "2783      154377 212636 334024 350747 696269 704564 1241...\n",
       "3105      603562 647574 792910 844605 863071 878798 1082..."
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_confirmed = train_confirmed.set_index('AuthorId')\n",
    "train_confirmed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_relation(author_id,paper_id):\n",
    "    relation_list = pd.DataFrame()\n",
    "    paper_author = dataset['paper_author']\n",
    "    pa_only = dataset['paper_author'][['PaperId','AuthorId']]\n",
    "    #find papers related to the author\n",
    "    related_papers = pa_only[pa_only.AuthorId == author_id]['PaperId'].unique()\n",
    "    print(\"# related papers:\",related_papers.shape)\n",
    "    \n",
    "    #find authors related to the paper\n",
    "    related_authors = paper_author[paper_author['PaperId'] == paper_id]['AuthorId'].unique()\n",
    "    print(\"# related authors:\",related_authors.shape)\n",
    "    \n",
    "    #remove target paper and target author from lists\n",
    "    related_papers = np.delete(related_papers,np.argwhere(related_papers == paper_id))\n",
    "    related_authors = np.delete(related_authors, np.argwhere(related_authors == author_id))\n",
    "    \n",
    "    print(\"# related papers:\",related_papers.shape)\n",
    "    print(\"# related authors:\",related_authors.shape)\n",
    "    cnt = 0\n",
    "    for author in related_authors:\n",
    "        for paper in related_papers:\n",
    "            single_relation = pa_only[(pa_only['PaperId'] == paper) & (pa_only['AuthorId'] == author)]\n",
    "            cnt += single_relation.size\n",
    "            \n",
    "    print(author_id,paper_id,\"->\",cnt)\n",
    "    \n",
    "    return cnt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time find_relation(826,25733)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
