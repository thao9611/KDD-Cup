{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Year</th>\n",
       "      <th>ConferenceId</th>\n",
       "      <th>JournalId</th>\n",
       "      <th>Keyword</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stitching videos streamed by mobile phones in ...</td>\n",
       "      <td>2009</td>\n",
       "      <td>167</td>\n",
       "      <td>0</td>\n",
       "      <td>mobile video capturing|real-time|video stitching</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A nonlocal convection窶電iffusion equation</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "      <td>7234</td>\n",
       "      <td>Nonlocal diffusion; Convection窶電iffusion; Asym...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Area Effects in Cepaea</td>\n",
       "      <td>1963</td>\n",
       "      <td>0</td>\n",
       "      <td>16867</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Multiple paternity in a natural population of ...</td>\n",
       "      <td>2005</td>\n",
       "      <td>0</td>\n",
       "      <td>6130</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Complexity of Finding Short Resolution Proofs</td>\n",
       "      <td>1997</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title  Year  ConferenceId  \\\n",
       "Id                                                                          \n",
       "1   Stitching videos streamed by mobile phones in ...  2009           167   \n",
       "2            A nonlocal convection窶電iffusion equation  2007             0   \n",
       "3                              Area Effects in Cepaea  1963             0   \n",
       "4   Multiple paternity in a natural population of ...  2005             0   \n",
       "5       Complexity of Finding Short Resolution Proofs  1997           158   \n",
       "\n",
       "    JournalId                                            Keyword  \n",
       "Id                                                                \n",
       "1           0   mobile video capturing|real-time|video stitching  \n",
       "2        7234  Nonlocal diffusion; Convection窶電iffusion; Asym...  \n",
       "3       16867                                                     \n",
       "4        6130                                                     \n",
       "5           0                                                     "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "paper = pd.read_csv(r\"C:\\Users\\Admin\\Downloads\\kdd cup\\dataRev\\Paper.csv\")[:2000]\n",
    "paper= paper.set_index(\"Id\")\n",
    "paper['Keyword']= paper['Keyword'].fillna(\"\")\n",
    "paper['Title']= paper['Title'].fillna(\"\")\n",
    "title = list(paper[\"Title\"])\n",
    "paper.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mobile', 'video', 'capturing|real-time|video', 'stitching']"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(paper.loc[1,'Keyword'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#preprocessing keywords\n",
    "def filter_keyword(text):\n",
    "    for i in string.punctuation: text = text.replace(i,' ')\n",
    "    words = word_tokenize(text) #split words\n",
    "    words = [w.lower() for w in words if w.isalpha()] #get rid of punctuation\n",
    "    words = [w for w in words if w not in  [\"keywords\"] ]\n",
    "    stemmed = [porter.stem(w) for w in words]\n",
    "    return stemmed\n",
    "paper['Keyword_pro'] = paper['Keyword'].map(filter_keyword)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "stopword = set(stopwords.words('english'))\n",
    "porter = PorterStemmer()\n",
    "def tokenize(text):\n",
    "    #text = text.split() # get single words \n",
    "    #table = maketrans('','',string.punctuation)\n",
    "    #stripped = [w.translate(table).lower() for w in text]#get rid of all punctuation\n",
    "    words = word_tokenize(text) #split words\n",
    "    words = [w.lower() for w in words if w.isalpha()] #get rid of punctuation\n",
    "    words =[w for w in words if  not w in stopword]\n",
    "    stemmed = [porter.stem(w) for w in words]\n",
    "    return stemmed\n",
    "paper['Token'] = paper.Title.map(tokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#concatenate keyword and token\n",
    "paper['Key_token'] = paper[['Keyword_pro','Token']].apply((lambda x: ' '.join(list(set([i for z in x for i in z])))), axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "token = list(paper['Key_token'])\n",
    "count = CountVectorizer(min_df = 5)\n",
    "tfidf = TfidfTransformer()\n",
    "count_token =count.fit_transform(token).toarray() #2000*527\n",
    "#tfid_token = tfidf.fit_transform(count_token)\n",
    "vocab = list(count.vocabulary_.keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id\n",
       "1    [real, stream, time, mobil, video]\n",
       "2                       [diffus, equat]\n",
       "3                        [effect, area]\n",
       "4       [storag, natur, multipl, popul]\n",
       "5              [find, resolut, complex]\n",
       "Name: Common word, dtype: object"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list of common words in each title of each document\n",
    "paper['Common word'] = paper['Key_token'].map(lambda x: [i for i in x.split() if i in vocab])\n",
    "paper.loc[:5,'Common word']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
